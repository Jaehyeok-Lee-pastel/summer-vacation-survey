# ğŸ“ summer_vacation_recommender.py
# ì—¬ë¦„ íœ´ê°€ ì¶”ì²œ ì‹œìŠ¤í…œ - ë¨¸ì‹ ëŸ¬ë‹ ê²°ê³¼ ê¸°ë°˜ êµ¬í˜„

import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import joblib
import pickle
import os
from datetime import datetime

class SummerVacationRecommender:
    def __init__(self):
        self.full_encoded_df = None
        self.features_encoded = None
        self.original_df = None
        self.feature_columns = None
        
        # ğŸ“‹ ë¨¸ì‹ ëŸ¬ë‹ ê²°ê³¼ì—ì„œ ì‚¬ìš©ëœ í•µì‹¬ íŠ¹ì§• 5ê°€ì§€
        self.selected_features = [
            'ì—°ë ¹ëŒ€',                    
            'ì„±ë³„',                      
            'í•¨ê»˜í•œ_ì‚¬ëŒ',               
            'íœ´ê°€_ì¥ì†Œ_êµ­ë‚´_í•´ì™¸',       
            'ê°€ì¥_ìµœê·¼_ì—¬ë¦„_íœ´ê°€'        
        ]
        
        # ğŸ¯ ë¨¸ì‹ ëŸ¬ë‹ ê²°ê³¼ì—ì„œ ë‚˜ì˜¨ ì¶”ì²œ ë°ì´í„°ë§Œ ì‚¬ìš©
        # ì‹¤ì œ ê²°ê³¼ì— ë‚˜íƒ€ë‚œ íœ´ê°€ ìœ í˜•ê³¼ ì§€ì—­ ì •ë³´
        self.vacation_results = {
            'í•´ìˆ˜ìš•, ë¬¼ë†€ì´ (ë°”ë‹¤/ì„¬ ì—¬í–‰)': {
                'ë™ì•„ì‹œì•„': ['ë™ì•„ì‹œì•„ ë°”ë‹¤/ì„¬ ì—¬í–‰ì§€'],
                'ì•„í”„ë¦¬ì¹´': ['ì•„í”„ë¦¬ì¹´ ë°”ë‹¤/ì„¬ ì—¬í–‰ì§€']
            },
            'ë“±ì‚°, ìº í•‘ ë“± ì•„ì›ƒë„ì–´ í™œë™ (ì‚°/ê³„ê³¡ ì—¬í–‰)': {
                'ë¶ë¯¸': ['ë¶ë¯¸ ì•„ì›ƒë„ì–´ í™œë™ì§€']
            },
            'ë§›ì§‘ íˆ¬ì–´ (ë§›ì§‘ íƒë°©, ì§€ì—­ íŠ¹ì‚°ë¬¼ ì²´í—˜)': {
                'ë™ë‚¨ì•„ì‹œì•„': ['ë™ë‚¨ì•„ì‹œì•„ ë§›ì§‘ íˆ¬ì–´']
            },
            'ë„ì‹œ ê´€ê´‘ (ì‡¼í•‘, ì¹´í˜, ì‹œë‚´ êµ¬ê²½)': {
                'ë™ì•„ì‹œì•„': ['ë™ì•„ì‹œì•„ ë„ì‹œ ê´€ê´‘ì§€']
            },
            'íœ´ì–‘Â·íë§ (ìŠ¤íŒŒ, ë¦¬ì¡°íŠ¸, íœì…˜ íœ´ì‹)': {
                'ë™ë‚¨ì•„ì‹œì•„': ['ë™ë‚¨ì•„ì‹œì•„ íœ´ì–‘ì§€'],
                'ì•„í”„ë¦¬ì¹´': ['ì•„í”„ë¦¬ì¹´ íœ´ì–‘ì§€']
            },
            'ì¹œì²™Â·ì§€ì¸ ë°©ë¬¸': {
                'ë¶ë¯¸': ['ë¶ë¯¸ ì§€ì—­']
            }
        }
    
    def load_and_preprocess_data(self, csv_path):
        """
        ğŸ“Š 1ë‹¨ê³„: CSV íŒŒì¼ ë¡œë“œ ë° ì „ì²˜ë¦¬
        """
        print(f"ğŸ“‚ ë°ì´í„° ë¡œë”©: {csv_path}")
        
        # CSV íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if not os.path.exists(csv_path):
            raise FileNotFoundError(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
        
        # ë°ì´í„° ë¡œë“œ
        self.original_df = pd.read_csv(csv_path)
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        print(f"ğŸ“Š ë°ì´í„° í¬ê¸°: {self.original_df.shape[0]}í–‰ {self.original_df.shape[1]}ì—´")
        print(f"ğŸ“‹ ì»¬ëŸ¼: {self.original_df.columns.tolist()}")
        
        # ê²°ì¸¡ê°’ í™•ì¸ ë° ì²˜ë¦¬
        missing_data = self.original_df.isnull().sum()
        if missing_data.any():
            print(f"âš ï¸ ê²°ì¸¡ê°’ ë°œê²¬:")
            for col, count in missing_data[missing_data > 0].items():
                print(f"   {col}: {count}ê°œ")
                # ê²°ì¸¡ê°’ì„ 'ê¸°íƒ€'ë¡œ ì²˜ë¦¬
                self.original_df[col] = self.original_df[col].fillna('ê¸°íƒ€')
        
        # ğŸ”„ ì „ì²´ ë°ì´í„° ì›-í•« ì¸ì½”ë”© (ê¸°ì¤€ í…œí”Œë¦¿)
        print("ğŸ”„ ì „ì²´ ë°ì´í„° ì›-í•« ì¸ì½”ë”© ì¤‘...")
        self.full_encoded_df = pd.get_dummies(self.original_df)
        print(f"âœ… ì¸ì½”ë”© ì™„ë£Œ: {len(self.full_encoded_df.columns)}ê°œ íŠ¹ì„±")
        
        # ğŸ¯ ì„ íƒëœ íŠ¹ì§•ë§Œìœ¼ë¡œ ì¸ì½”ë”©
        print(f"ğŸ¯ í•µì‹¬ íŠ¹ì§• ì„ íƒ: {self.selected_features}")
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” íŠ¹ì§•ë§Œ í•„í„°ë§
        available_features = [feat for feat in self.selected_features 
                             if feat in self.original_df.columns]
        
        if len(available_features) != len(self.selected_features):
            missing_features = set(self.selected_features) - set(available_features)
            print(f"âš ï¸ ëˆ„ë½ëœ íŠ¹ì§•: {missing_features}")
            self.selected_features = available_features
            print(f"ğŸ”§ ì‚¬ìš©í•  íŠ¹ì§•: {self.selected_features}")
        
        # ì„ íƒëœ íŠ¹ì§•ë§Œìœ¼ë¡œ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        features_df = self.original_df[self.selected_features]
        self.features_encoded = pd.get_dummies(features_df)
        self.feature_columns = self.features_encoded.columns.tolist()
        
        print(f"âœ… íŠ¹ì§• ì¸ì½”ë”© ì™„ë£Œ: {len(self.features_encoded.columns)}ê°œ íŠ¹ì„±")
        print(f"ğŸ“Š ì¸ì½”ë”©ëœ íŠ¹ì§• ì˜ˆì‹œ: {self.feature_columns[:5]}")
        
        return self.original_df
    
    def find_similar_users(self, new_user_data, top_k=5):
        """
        ğŸ¯ 2ë‹¨ê³„: ìƒˆë¡œìš´ ì‚¬ìš©ìì™€ ìœ ì‚¬í•œ ê³ ê° ì°¾ê¸° (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
        """
        print("ğŸ” ìœ ì‚¬í•œ ê³ ê° ê²€ìƒ‰ ì¤‘...")
        
        if self.features_encoded is None:
            raise ValueError("âŒ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_and_preprocess_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        
        # ìƒˆë¡œìš´ ì‚¬ìš©ì ë°ì´í„°ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        new_user_df = pd.DataFrame([new_user_data])
        print(f"ğŸ‘¤ ìƒˆë¡œìš´ ì‚¬ìš©ì ë°ì´í„°:")
        for key, value in new_user_data.items():
            print(f"   {key}: {value}")
        
        # ì „ì²´ ì»¬ëŸ¼ ê¸°ì¤€ìœ¼ë¡œ ì›-í•« ì¸ì½”ë”©
        new_user_encoded = pd.get_dummies(new_user_df).reindex(
            columns=self.full_encoded_df.columns, fill_value=0
        )
        
        # ì„ íƒëœ íŠ¹ì§•ë§Œ ì¶”ì¶œ
        cols_to_keep = [col for col in self.full_encoded_df.columns 
                       if col in self.features_encoded.columns]
        
        new_user_features = new_user_encoded[cols_to_keep]
        
        # íŠ¹ì„± ë²¡í„° ì°¨ì› ë§ì¶”ê¸°
        new_user_features = new_user_features.reindex(
            columns=self.features_encoded.columns, fill_value=0
        )
        
        print(f"ğŸ”„ ì‚¬ìš©ì ë°ì´í„° ì¸ì½”ë”© ì™„ë£Œ: {new_user_features.shape}")
        
        # ğŸ¯ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        print("ğŸ§® ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ì¤‘...")
        similarity_scores = cosine_similarity(new_user_features, self.features_encoded)
        
        # ìœ ì‚¬ë„ ì ìˆ˜ë¡œ ì •ë ¬ (ë†’ì€ ìˆœ)
        top_indices = similarity_scores[0].argsort()[::-1][:top_k]
        
        print(f"âœ… ìƒìœ„ {top_k}ëª… ìœ ì‚¬ ê³ ê° ë°œê²¬!")
        
        # ê²°ê³¼ ì •ë¦¬
        similar_users = []
        for i, index in enumerate(top_indices):
            similarity_score = similarity_scores[0][index]
            user_info = self.original_df.iloc[index].to_dict()
            
            similar_users.append({
                'rank': i + 1,
                'similarity_score': round(similarity_score, 2),
                'user_data': user_info
            })
        
        return similar_users
    
    def get_recommendations(self, similar_users, exclude_low_satisfaction=True):
        """
        ğŸ 3ë‹¨ê³„: ì¶”ì²œ ìƒì„± (ë§Œì¡±ë„ ë‚®ì€ ì •ë³´ ì œì™¸)
        """
        print("ğŸ ì¶”ì²œ ê²°ê³¼ ìƒì„± ì¤‘...")
        
        recommendations = []
        
        for user in similar_users:
            user_data = user['user_data']
            
            # ë§Œì¡±ë„ ë‚®ì€ ê³ ê° ì œì™¸ (ë¨¸ì‹ ëŸ¬ë‹ ê²°ê³¼ ë°©ì‹ ì ìš©)
            if exclude_low_satisfaction:
                satisfaction = user_data.get('ë§Œì¡±ë„', '')
                if satisfaction in ['ë¶ˆë§Œì¡±', 'ë§¤ìš° ë¶ˆë§Œì¡±']:
                    print(f"âš ï¸ {user['rank']}ìœ„ ê³ ê° ì œì™¸ (ë§Œì¡±ë„: {satisfaction})")
                    continue
            
            # ì¶”ì²œ ì •ë³´ ì •ë¦¬ (ë¨¸ì‹ ëŸ¬ë‹ ê²°ê³¼ í˜•ì‹ ê·¸ëŒ€ë¡œ)
            recommendation = {
                'rank': user['rank'],
                'similarity_score': user['similarity_score'],
                'age_group': user_data.get('ì—°ë ¹ëŒ€', 'ì •ë³´ ì—†ìŒ'),
                'gender': user_data.get('ì„±ë³„', 'ì •ë³´ ì—†ìŒ'),
                'recent_vacation': user_data.get('ê°€ì¥_ìµœê·¼_ì—¬ë¦„_íœ´ê°€', 'ì •ë³´ ì—†ìŒ'),
                'location_type': user_data.get('íœ´ê°€_ì¥ì†Œ_êµ­ë‚´_í•´ì™¸', 'ì •ë³´ ì—†ìŒ'),
                'location': user_data.get('íœ´ê°€_ì¥ì†Œ', 'ì •ë³´ ì—†ìŒ'),
                'transportation': user_data.get('ì£¼ìš”_êµí†µìˆ˜ë‹¨', 'ì •ë³´ ì—†ìŒ'),
                'duration': user_data.get('íœ´ê°€_ê¸°ê°„', 'ì •ë³´ ì—†ìŒ'),
                'companion': user_data.get('í•¨ê»˜í•œ_ì‚¬ëŒ', 'ì •ë³´ ì—†ìŒ'),
                'budget': user_data.get('ì´_ë¹„ìš©', 'ì •ë³´ ì—†ìŒ'),
                'satisfaction': user_data.get('ë§Œì¡±ë„', 'ì •ë³´ ì—†ìŒ'),
                'next_preference': user_data.get('ë‹¤ìŒ_íœ´ê°€_ê²½í—˜', 'ì •ë³´ ì—†ìŒ')
            }
            
            recommendations.append(recommendation)
        
        print(f"âœ… {len(recommendations)}ê°œ ì¶”ì²œ ìƒì„± ì™„ë£Œ!")
        return recommendations
    
    def save_model(self, model_dir='./ml_models/'):
        """
        ğŸ’¾ ëª¨ë¸ ë° ë°ì´í„° ì €ì¥ (Djangoì—ì„œ ì‚¬ìš©í•˜ë„ë¡)
        """
        print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘... ê²½ë¡œ: {model_dir}")
        
        # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(model_dir, exist_ok=True)
        
        # 1. ì¸ì½”ë”©ëœ íŠ¹ì§• ë°ì´í„° ì €ì¥
        features_path = os.path.join(model_dir, 'features_encoded.pkl')
        joblib.dump(self.features_encoded, features_path)
        print(f"âœ… íŠ¹ì§• ë°ì´í„° ì €ì¥: {features_path}")
        
        # 2. ì „ì²´ ì¸ì½”ë”© í…œí”Œë¦¿ ì €ì¥
        template_path = os.path.join(model_dir, 'encoding_template.pkl')
        joblib.dump(self.full_encoded_df.columns.tolist(), template_path)
        print(f"âœ… ì¸ì½”ë”© í…œí”Œë¦¿ ì €ì¥: {template_path}")
        
        # 3. ì›ë³¸ ë°ì´í„° ì €ì¥
        original_path = os.path.join(model_dir, 'original_data.pkl')
        joblib.dump(self.original_df, original_path)
        print(f"âœ… ì›ë³¸ ë°ì´í„° ì €ì¥: {original_path}")
        
        # 4. ì„ íƒëœ íŠ¹ì§• ì €ì¥
        selected_features_path = os.path.join(model_dir, 'selected_features.pkl')
        joblib.dump(self.selected_features, selected_features_path)
        print(f"âœ… ì„ íƒëœ íŠ¹ì§• ì €ì¥: {selected_features_path}")
        
        # 5. íœ´ê°€ ê²°ê³¼ ë°ì´í„° ì €ì¥ (ë¨¸ì‹ ëŸ¬ë‹ ê²°ê³¼ ê¸°ë°˜)
        vacation_results_path = os.path.join(model_dir, 'vacation_results.pkl')
        joblib.dump(self.vacation_results, vacation_results_path)
        print(f"âœ… íœ´ê°€ ê²°ê³¼ ë°ì´í„° ì €ì¥: {vacation_results_path}")
        
        # 6. ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'model_type': 'CosineSimilarityRecommender',
            'algorithm': 'Cosine Similarity',
            'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'selected_features': self.selected_features,
            'total_users': len(self.original_df) if self.original_df is not None else 0,
            'total_features': len(self.features_encoded.columns) if self.features_encoded is not None else 0,
            'data_columns': self.original_df.columns.tolist() if self.original_df is not None else [],
            'vacation_types': list(self.vacation_results.keys())
        }
        
        metadata_path = os.path.join(model_dir, 'metadata.pkl')
        with open(metadata_path, 'wb') as f:
            pickle.dump(metadata, f)
        print(f"âœ… ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_path}")
        
        print(f"ğŸ‰ ëª¨ë“  íŒŒì¼ ì €ì¥ ì™„ë£Œ!")
        print(f"ğŸ“ ì €ì¥ëœ íŒŒì¼ë“¤:")
        for file in os.listdir(model_dir):
            file_path = os.path.join(model_dir, file)
            file_size = os.path.getsize(file_path) / 1024  # KB
            print(f"   ğŸ“„ {file} ({file_size:.1f} KB)")
    
    def print_recommendations(self, recommendations):
        """
        ğŸ“‹ ì¶”ì²œ ê²°ê³¼ë¥¼ ë¨¸ì‹ ëŸ¬ë‹ ê²°ê³¼ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
        """
        print("\n" + "="*60)
        print("--- ê°€ì¥ ìœ ì‚¬í•œ ê³ ê° ì •ë³´ ---")
        print("="*60)
        
        for rec in recommendations:
            print(f"\n[{rec['rank']}ìœ„ ê³ ê° ì •ë³´]")
            print(f"ìœ ì‚¬ë„ ì ìˆ˜: {rec['similarity_score']}")
            print(f"  - ì—°ë ¹ëŒ€: {rec['age_group']}")
            print(f"  - ì„±ë³„: {rec['gender']}")
            print(f"  - ê°€ì¥_ìµœê·¼_ì—¬ë¦„_íœ´ê°€: {rec['recent_vacation']}")
            print(f"  - íœ´ê°€_ì¥ì†Œ_êµ­ë‚´_í•´ì™¸: {rec['location_type']}")
            print(f"  - íœ´ê°€_ì¥ì†Œ: {rec['location']}")
            print(f"  - ì£¼ìš”_êµí†µìˆ˜ë‹¨: {rec['transportation']}")
            print(f"  - íœ´ê°€_ê¸°ê°„: {rec['duration']}")
            print(f"  - í•¨ê»˜í•œ_ì‚¬ëŒ: {rec['companion']}")
            print(f"  - ì´_ë¹„ìš©: {rec['budget']}")
            print(f"  - ë§Œì¡±ë„: {rec['satisfaction']}")
            print(f"  - ë‹¤ìŒ_í¬ë§_íœ´ê°€: {rec['next_preference']}")

# =============================================================================
# ğŸš€ ì‹¤í–‰ ì½”ë“œ (ë°ì´í„° ë¶„ì„ê°€ê°€ ì‹¤í–‰í•  ë¶€ë¶„)
# =============================================================================

if __name__ == "__main__":
    print("ğŸ¯ ì—¬ë¦„ íœ´ê°€ ì¶”ì²œ ì‹œìŠ¤í…œ - ë¨¸ì‹ ëŸ¬ë‹ ê²°ê³¼ ê¸°ë°˜!")
    print("=" * 60)
    
    # 1ï¸âƒ£ ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    recommender = SummerVacationRecommender()
    
    # 2ï¸âƒ£ CSV íŒŒì¼ ê²½ë¡œ ì„¤ì • (ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½)
    csv_file_path = 'survey_data.csv'  # ğŸ‘ˆ ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½
    
    try:
        # 3ï¸âƒ£ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        df = recommender.load_and_preprocess_data(csv_file_path)
        
        # 4ï¸âƒ£ ìƒˆë¡œìš´ ê³ ê° ë°ì´í„° (ë°±ì—”ë“œì—ì„œ ì‹¤ì œ ì‚¬ìš©ì ë°ì´í„°ë¡œ êµì²´ ì˜ˆì •)
        # ë¨¸ì‹ ëŸ¬ë‹ ê²°ê³¼ì— ë‚˜ì˜¨ í˜•ì‹ê³¼ ë™ì¼í•˜ê²Œ ì„¤ì •
        new_user_data = {
            'ì—°ë ¹ëŒ€': '20ëŒ€',
            'ì„±ë³„': 'ì—¬ì„±',
            'ê°€ì¥_ìµœê·¼_ì—¬ë¦„_íœ´ê°€': 'í•´ìˆ˜ìš•, ë¬¼ë†€ì´ (ë°”ë‹¤/ì„¬ ì—¬í–‰)',
            'íœ´ê°€_ì¥ì†Œ_êµ­ë‚´_í•´ì™¸': 'í•´ì™¸',
            'íœ´ê°€_ì¥ì†Œ': 'ë™ì•„ì‹œì•„',
            'ì£¼ìš”_êµí†µìˆ˜ë‹¨': 'í•­ê³µí¸',
            'íœ´ê°€_ê¸°ê°„': '4~6ì¼',
            'í•¨ê»˜í•œ_ì‚¬ëŒ': 'ê°€ì¡±',
            'ì´_ë¹„ìš©': '30ë§Œ~50ë§Œ ì›',
            'ë§Œì¡±ë„': 'ë§¤ìš° ë§Œì¡±',
            'ë‹¤ìŒ_íœ´ê°€_ê²½í—˜': 'ë„ì‹œ ê´€ê´‘ (ì‡¼í•‘, ì¹´í˜, ì‹œë‚´ êµ¬ê²½)'
        }
        
        # 5ï¸âƒ£ ìœ ì‚¬í•œ ê³ ê° ì°¾ê¸° (ìƒìœ„ 5ëª…)
        similar_users = recommender.find_similar_users(new_user_data, top_k=5)
        
        # 6ï¸âƒ£ ì¶”ì²œ ìƒì„± (ë§Œì¡±ë„ ë‚®ì€ ê³ ê° ì œì™¸)
        recommendations = recommender.get_recommendations(
            similar_users, exclude_low_satisfaction=True
        )
        
        # 7ï¸âƒ£ ë¨¸ì‹ ëŸ¬ë‹ ê²°ê³¼ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
        recommender.print_recommendations(recommendations)
        
        # 8ï¸âƒ£ ëª¨ë¸ ì €ì¥ (Djangoì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡)
        recommender.save_model('./ml_models/')
        
        print("\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
        print("ğŸ“¦ Django í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©í•  íŒŒì¼ë“¤ì´ ml_models/ í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("ğŸš€ ì´ì œ ë°±ì—”ë“œ ê°œë°œíŒ€ì´ ì´ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
        
    except FileNotFoundError as e:
        print(f"âŒ íŒŒì¼ ì˜¤ë¥˜: {e}")
        print("ğŸ’¡ í•´ê²°ë°©ë²•:")
        print("   1. CSV íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”")
        print("   2. íŒŒì¼ëª…ì´ 'survey_data.csv'ì¸ì§€ í™•ì¸í•˜ì„¸ìš”")
        
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        print("ğŸ’¡ ì˜¤ë¥˜ë¥¼ ê°œë°œíŒ€ê³¼ ê³µìœ í•´ì£¼ì„¸ìš”!")
        import traceback
        traceback.print_exc()